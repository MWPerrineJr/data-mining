{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4cc355",
   "metadata": {},
   "source": [
    "#### Michael Perrine \n",
    "#### Week 11 Assignment\n",
    "#### DSC 550\n",
    "#### Professor Warner\n",
    "\n",
    "\n",
    "<h1><center>Image Analysis</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "615ca201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow import estimator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix,r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed26292",
   "metadata": {},
   "source": [
    "1. Import data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd6fe95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create the X_train, X_test, y_train, _y_test\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape or dimensions of X_train :3\n",
      "Number of samples in our training data set :60000\n",
      "Number of samples in our training data set :60000\n",
      "Number of samples in our training data set :10000\n",
      "Number of samples in our training data set :10000\n",
      "\n",
      "Dimensions of X_train :(28, 28)\n",
      "Labels in X_train :(60000,)\n",
      "\n",
      "Dimensions of X_test :(28, 28)\n",
      "Labels in y_test :(10000,)\n"
     ]
    }
   ],
   "source": [
    "# this series of code prints out the length of the X_train, X_test, y_train and y_test\n",
    "print('Initial shape or dimensions of X_train :' + str(len(X_train.shape)))\n",
    "\n",
    "print('Number of samples in our training data set :' + str(len(X_train)))\n",
    "print('Number of samples in our training data set :' + str(len(y_train)))\n",
    "print('Number of samples in our training data set :' + str(len(X_test)))\n",
    "print('Number of samples in our training data set :' + str(len(y_test)))\n",
    "print()\n",
    "print('Dimensions of X_train :' + str(X_train[0].shape))\n",
    "print('Labels in X_train :' + str(y_train.shape))\n",
    "print()\n",
    "print('Dimensions of X_test :' + str(X_test[0].shape))\n",
    "print('Labels in y_test :' + str(y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecdab2",
   "metadata": {},
   "source": [
    "2. Display the first 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4faa656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code displays the first five numbers and their labels\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534a8e9",
   "metadata": {},
   "source": [
    "3. Build and train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b4118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.3985 - accuracy: 0.9297 - val_loss: 0.1191 - val_accuracy: 0.9680\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0870 - accuracy: 0.9748 - val_loss: 0.0686 - val_accuracy: 0.9797\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 0.0630 - val_accuracy: 0.9824\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.0726 - val_accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2879f467278>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following series of code builds and trains the CNN model\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# This section adds the batch dimension\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# This section creates the one-hot encoding for the labels\n",
    "y_train = to_categorical(y_train, num_classes=None)\n",
    "y_test = to_categorical(y_test, num_classes=None)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# this section fits model using Keras\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 5, activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(32, 5, activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "    loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, \n",
    "    batch_size=32, validation_data=(X_test, y_test), epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 31,594\n",
      "Trainable params: 31,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This code displays the output summary for the CNN\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates the y_pred object\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax (y_pred, axis = 1)\n",
    "y_test=np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd269a",
   "metadata": {},
   "source": [
    "4. Report the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa49e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623860928891965"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code calculates \n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552d8b9",
   "metadata": {},
   "source": [
    "5. Build a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.83805668e-01 0.00000000e+00 4.83091787e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.11193242e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.00502513e-03]\n",
      " [0.00000000e+00 9.91189427e-01 0.00000000e+00 3.90625000e-03\n",
      "  0.00000000e+00 1.10741971e-03 2.11193242e-03 1.96270854e-03\n",
      "  1.01214575e-03 0.00000000e+00]\n",
      " [3.03643725e-03 8.81057269e-04 9.83574879e-01 2.92968750e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.94406281e-03\n",
      "  4.04858300e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.76562500e-01\n",
      "  0.00000000e+00 7.75193798e-03 0.00000000e+00 1.96270854e-03\n",
      "  1.01214575e-03 0.00000000e+00]\n",
      " [0.00000000e+00 8.81057269e-04 9.66183575e-04 0.00000000e+00\n",
      "  9.90683230e-01 0.00000000e+00 6.33579725e-03 0.00000000e+00\n",
      "  6.07287449e-03 1.10552764e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.76562500e-03\n",
      "  0.00000000e+00 9.70099668e-01 1.05596621e-03 9.81354269e-04\n",
      "  2.02429150e-03 2.01005025e-03]\n",
      " [7.08502024e-03 1.76211454e-03 9.66183575e-04 1.95312500e-03\n",
      "  3.10559006e-03 5.53709856e-03 9.88384372e-01 0.00000000e+00\n",
      "  2.02429150e-03 0.00000000e+00]\n",
      " [0.00000000e+00 1.76211454e-03 6.76328502e-03 2.92968750e-03\n",
      "  1.03519669e-03 0.00000000e+00 0.00000000e+00 9.85279686e-01\n",
      "  3.03643725e-03 8.04020101e-03]\n",
      " [3.03643725e-03 0.00000000e+00 0.00000000e+00 9.76562500e-04\n",
      "  1.03519669e-03 2.21483942e-03 0.00000000e+00 1.96270854e-03\n",
      "  9.74696356e-01 2.01005025e-03]\n",
      " [3.03643725e-03 3.52422907e-03 2.89855072e-03 9.76562500e-04\n",
      "  4.14078675e-03 1.32890365e-02 0.00000000e+00 4.90677134e-03\n",
      "  6.07287449e-03 9.75879397e-01]]\n"
     ]
    }
   ],
   "source": [
    "# This code creates a confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_pred, normalize='pred')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde49f0",
   "metadata": {},
   "source": [
    "6. Summarize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950dc86",
   "metadata": {},
   "source": [
    "CNN is a neural network that is used to identify images. For this analysis I used the CNN to analyze the mnist dataset. This is a data set of 60,000 handwritten numbers. I ran four epochs of the data and got an accuracy range from 92.97% to 98.15%. The results are promising. To validate my results I also ran an R-squared with the y_test and y_pred object. The result scored a 96.23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
